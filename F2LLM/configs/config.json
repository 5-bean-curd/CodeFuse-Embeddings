{
  "model_path": "models/bert",
  "experiment_id": "bert+lr.8e-6+bs.16x32+context.1024+1epochs",
  "train_data_path": "data_tokenized_bert",
  "output_dir": "output",
  "tb_dir": "output/tb",
  "cache_dir": "cache",
  "train_batch_size": 16,
  "checkpointing_steps": 5000,
  "validation_steps": 5000,
  "max_seq_length": 1024,
  "learning_rate": 8e-6,
  "min_lr": 1e-7,
  "weight_decay": 0.01,
  "warmup_steps": 500,
  "train_epochs": 2,
  "log_interval": 100,
  "num_hard_neg": 7
}
